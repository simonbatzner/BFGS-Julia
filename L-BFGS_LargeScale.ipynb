{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\">18.335/6.337 Final Project - The L-BFGS algorithm</div>\n",
    "##  <div style=\"text-align: center\">Large-Scale Problem (using Strong Wolfe Line-Search)</div>\n",
    "### <div style=\"text-align: center\">Created by Yusu Liu and Simon Batzner</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import test functions and set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lbfgs! (generic function with 4 methods)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lbfgs!(F, x0, maxIt, m, save_pos = 1, τgrad=1e-8, verbose = 0)\n",
    "    #INPUT\n",
    "    # F: function to be optimized\n",
    "    # x0: initial guess\n",
    "    # maxIt: maximum Iteration\n",
    "    # m: last m input differences and gradient differences are stored\n",
    "    # τgrad: tolerance for norm of the slope\n",
    "\n",
    "\n",
    "    #OUTPUT\n",
    "    #x1: optimized variable\n",
    "    #f1: function value at x1\n",
    "    #k iteration number\n",
    "    n = size(x0, 1)\n",
    "    pos = zeros(maxIt, n)\n",
    "    k=0\n",
    "    n=length(x0)\n",
    "    Sm=zeros(n,m) #S_k=x_k+1-x_k\n",
    "    Ym=zeros(n,m) #Y_k=g_k+1-g_k\n",
    "\n",
    "    f0,g0 = F(x0)\n",
    "    #use the simplest line search to find step size\n",
    "    α, f1, g1=strongwolfe(F,-g0,x0,f0,g0)\n",
    "    x1 = x0 - α.*g0\n",
    "    k=1\n",
    "    if save_pos == 1\n",
    "        pos[1, :] = x0\n",
    "        pos[2, :] = x1\n",
    "    end\n",
    "\n",
    "    while true\n",
    "       if k>maxIt\n",
    "           break\n",
    "       end\n",
    "       gnorm=norm(g0)\n",
    "       if gnorm < τgrad\n",
    "           break\n",
    "       end\n",
    "       s0=x1-x0\n",
    "       y0=g1-g0\n",
    "       #println(\"y0=$y0\")\n",
    "\n",
    "       H0=s0'*y0/(y0'*y0) #hessian diagonal satisfying secant condition\n",
    "       # println(H0)\n",
    "       # if H0<0\n",
    "       #     H0=1\n",
    "       # end\n",
    "       # println(H0)\n",
    "       #update Sm and Ym\n",
    "       if k<=m\n",
    "           Sm[:,k]=s0\n",
    "           Ym[:,k]=y0\n",
    "           p=-approxInvHess(g1,Sm[:,1:k],Ym[:,1:k],H0)\n",
    "       # only keep m entries in Sm and Ym so purge the old ones\n",
    "       elseif (k>m)\n",
    "           Sm[:,1:(m-1)]=Sm[:,2:m]\n",
    "           Ym[:,1:(m-1)]=Sm[:,2:m]\n",
    "           Sm[:,m]=s0\n",
    "           Ym[:,m]=y0\n",
    "           p=-approxInvHess(g1,Sm,Ym,H0)\n",
    "       end\n",
    "       # new direction=p, find new step size\n",
    "       α, fs, gs=strongwolfe(F,p,x1,f1,g1)\n",
    "       #update for next iteration\n",
    "       x0=x1\n",
    "       g0=g1\n",
    "       x1=x1+α.*p\n",
    "       pos[k+1, :] = x1\n",
    "       f1=fs\n",
    "       g1=gs\n",
    "       k=k+1\n",
    "\n",
    "       if verbose == 1\n",
    "           println(\"It=$k,x=$x1\")\n",
    "        end\n",
    "    end\n",
    "\n",
    "    k=k-1\n",
    "    if save_pos == 1\n",
    "        return x1, f1, k, pos\n",
    "    else \n",
    "        return x1, f1, k\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strongwolfe (generic function with 2 methods)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function strongwolfe(F,d,x0,fx0,gx0,maxIt=100)\n",
    "   α_m=20\n",
    "   α_p=0\n",
    "   c1=1e-4\n",
    "   c2=0.9\n",
    "   α_x=1\n",
    "   gx0=copy(gx0'*d)\n",
    "   fxp=copy(fx0)\n",
    "   gxp=copy(gx0)\n",
    "   i=1\n",
    "   α_s=0\n",
    "   fs=copy(fx0)\n",
    "   gs=copy(gx0)\n",
    "   while true\n",
    "       xx=x0+α_x*d\n",
    "       fxx,gxx=F(xx)\n",
    "       fs=copy(fxx)\n",
    "       gs=copy(gxx)\n",
    "       gxx=copy(gxx'*d)\n",
    "\n",
    "       if (fxx>(fx0+c1*α_x*gx0)[1]) || (i>1) & (fxx>=fxp)\n",
    "           α_s,fs,gs=zoom(F,x0,d,α_p,α_x,fx0,gx0)\n",
    "           return α_s,fs,gs\n",
    "       end\n",
    "       if abs(gxx)<=-c2*(gx0)\n",
    "           α_s=copy(α_x)\n",
    "           return α_s,fs,gs\n",
    "       end\n",
    "       if gxx>=0\n",
    "       #if abs.(gxx)[1]>=0 && abs.(gxx)[2]>=0\n",
    "           α_s,fs,gs=zoom(F,x0,d,α_x,α_p,fx0,gx0)\n",
    "           return α_s,fs,gs\n",
    "       end\n",
    "       α_p=copy(α_x)\n",
    "       fxp=copy(fxx)\n",
    "       gxp=copy(gxx)\n",
    "\n",
    "       if i>maxIt\n",
    "           α_s=α_x\n",
    "           return α_s,fs,gs\n",
    "\n",
    "       end\n",
    "       r=0.8\n",
    "       #r=0.8\n",
    "       α_x=α_x+(α_m-α_x)*r\n",
    "       i=i+1\n",
    "\n",
    "   end\n",
    "   return α_s,fs,gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zoom (generic function with 2 methods)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function zoom(F,x0,d,α_l,α_h,fx0,gx0,maxIt=10)\n",
    "   c1=1e-4\n",
    "   c2=0.9\n",
    "   i=0\n",
    "   α_s=0\n",
    "   fs=copy(fx0)\n",
    "   gs=copy(gx0)\n",
    "   while true\n",
    "       α_x=0.5*(α_l+α_h)\n",
    "       α_s=copy(α_x)\n",
    "       xx=x0+α_x*d\n",
    "       fxx,gxx=F(xx)\n",
    "       fs=copy(fxx)\n",
    "       gs=copy(gxx)\n",
    "       gxx=gxx'*d\n",
    "       xl=x0+α_l*d\n",
    "       fxl,gxl=F(xl)\n",
    "       if (fxx>(fx0+c1*α_x*gx0)[1]) || fxx>=fxl\n",
    "           α_h=copy(α_x)\n",
    "       else\n",
    "           if abs(gxx)[1]<=-c2*(gx0)\n",
    "               α_s=copy(α_x)\n",
    "               return α_s,fs,gs\n",
    "           end\n",
    "           if gxx*(α_h-α_l)[1]>=0\n",
    "               α_h=copy(α_l)\n",
    "           end\n",
    "           α_l=copy(α_x)\n",
    "       end\n",
    "       i=i+1\n",
    "       if i>maxIt\n",
    "           α_s=copy(α_x)\n",
    "           return α_s,fs,gs\n",
    "       end\n",
    "   end\n",
    "\n",
    "   return α_s,fs,gs\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approxInvHess (generic function with 2 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function approxInvHess(g,S,Y,H0,n=2)\n",
    "    #INPUT\n",
    "\n",
    "    #g: gradient nx1 vector\n",
    "    #S: nxk matrixs storing S[i]=x[i+1]-x[i]\n",
    "    #Y: nxk matrixs storing Y[i]=g[i+1]-g[i]\n",
    "    #H0: initial hessian diagnol scalar\n",
    "\n",
    "    #OUTPUT\n",
    "    # p:  the approximate inverse hessian multiplied by the gradient g\n",
    "    #     which is the new direction\n",
    "    #notation follows:\n",
    "    #https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
    "\n",
    "    n,k=size(S)\n",
    "    rho=zeros(k)\n",
    "    for i=1:k\n",
    "        rho[i].=abs(1/(Y[:,i]'*S[:,i]))\n",
    "    end\n",
    "\n",
    "\n",
    "    q=zeros(n,k+1)\n",
    "    r=zeros(n,1)\n",
    "    α=zeros(k,1)\n",
    "    β=zeros(k,1)\n",
    "\n",
    "    q[:,k+1]=g\n",
    "\n",
    "    for i=k:-1:1\n",
    "        α[i].=rho[i]*S[:,i]'*q[:,i+1]\n",
    "        q[:,i].=q[:,i+1]-α[i]*Y[:,i]\n",
    "    end\n",
    "\n",
    "    z=zeros(n)\n",
    "    z.=H0*q[:,1]\n",
    "\n",
    "\n",
    "    for i=1:k\n",
    "        β[i].=rho[i]*Y[:,i]'*z\n",
    "        z.=z+S[:,i]*(α[i]-β[i])\n",
    "    end\n",
    "\n",
    "    p=copy(z)\n",
    "\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final f was 1108.1947187850126\n",
      "\n",
      "===============================================================\n",
      "Results:\n",
      "===============================================================\n",
      "* Algorithm: L-BFGS w/ StrongWolfe - own implementation\n",
      " * Function: Engvall with n = 1000\n",
      " * Minimum: 1108.1947187850126\n",
      " * Iterations: 34\n",
      " * Convergence to within 1: conv\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "\n",
    "##################\n",
    "include(\"engvall.jl\")\n",
    "x0 = rand(n); \n",
    "tol = 1\n",
    "m = 2\n",
    "t = 0.0\n",
    "tol = 1\n",
    "bool = false\n",
    "\n",
    "if n === 1000\n",
    "    x1, f1, k, pos=lbfgs!(engvall_1000, x0, 1000, m); \n",
    "    pos = pos[1:(k+1), :]; \n",
    "    t += @elapsed lbfgs!(engvall_1000, x0, 1000, m); \n",
    "    \n",
    "    if norm(f1 - 1108) > tol\n",
    "        bool = false\n",
    "    else\n",
    "        bool = true\n",
    "    end\n",
    "    fun = \"Engvall with n = $n\"\n",
    "    \n",
    "    println(\"Final f was $f1\")\n",
    "elseif n === 5000\n",
    "    x1, f1, k, pos=lbfgs!(engvall_5000, x0, 1000, m); \n",
    "    pos = pos[1:(k+1), :]; \n",
    "    t += @elapsed lbfgs!(engvall_5000, x0, 1000, m); \n",
    "    \n",
    "    if norm(f1 - 5548) > tol\n",
    "        bool = false\n",
    "    else\n",
    "        bool = true\n",
    "    end\n",
    "    fun = \"Engvall with n = $n\"\n",
    "    \n",
    "    println(\"Final f was $f1\")\n",
    "end\n",
    " \n",
    "println(\"\\n===============================================================\\nResults:\\n===============================================================\")\n",
    "println(\"* Algorithm: L-BFGS w/ StrongWolfe - own implementation\")\n",
    "println(\" * Function: $(fun)\")\n",
    "println(\" * Minimum: $(f1)\")\n",
    "println(\" * Iterations: $(k)\")\n",
    "println(\" * Convergence to within $(tol): $(conv)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engvall_5000 (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function engvall_1000(x::Vector)\n",
    "    # fmin=1108\n",
    "    F=0.0\n",
    "    f=zeros(n-1)\n",
    "    for i=2:n\n",
    "        f=((x[i-1])^2+(x[i])^2)^2-4*(x[i-1])+3\n",
    "\n",
    "        F +=f\n",
    "    end\n",
    "    return F\n",
    "end\n",
    "\n",
    "function engvall_5000(x::Vector)\n",
    "    # fmin=5548\n",
    "    F=0.0\n",
    "    f=zeros(n-1)\n",
    "    for i=2:n\n",
    "        f=((x[i-1])^2+(x[i])^2)^2-4*(x[i-1])+3\n",
    "\n",
    "        F +=f\n",
    "    end\n",
    "    return F\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim, LineSearches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optim.jl's default (will not converge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Nelder-Mead\n",
       " * Starting Point: [0.6293337695370573,0.9028302053334671, ...]\n",
       " * Minimizer: [0.6300581739109379,0.8984317807571145, ...]\n",
       " * Minimum: 1.632738e+03\n",
       " * Iterations: 1000\n",
       " * Convergence: false\n",
       "   *  √(Σ(yᵢ-ȳ)²)/n < 1.0e-08: false\n",
       "   * Reached Maximum Number of Iterations: true\n",
       " * Objective Calls: 2184"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1000\n",
    "x0 = rand(n);\n",
    "result = optimize(x -> engvall_1000(x), x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method from Optim.jl for n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### DID NOT CONVERGE!!! ###\n",
    "# n = 1000\n",
    "# ########################################################################################################\n",
    "# k_tot = 0 \n",
    "# n_x0 = 1\n",
    "\n",
    "# for i = 1:n_x0\n",
    "    \n",
    "#     x0 = rand(n); \n",
    "#     result=optimize(x -> engvall_1000(x), x0, Newton(),Optim.Options(extended_trace=true,show_every=0,store_trace = true))  \n",
    "#     k_tot += result.iterations\n",
    "    \n",
    "# end\n",
    "# println(\"Average number of iterations for $(fun) averaged over $(n_x0) iterations: $(k_tot/n_x0)\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method from Optim.jl for n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 5000\n",
    "# ########################################################################################################\n",
    "# k_tot = 0 \n",
    "\n",
    "# for i = 1:n_x0\n",
    "    \n",
    "#     x0 = rand(n); \n",
    "#     result=optimize(x -> engvall_5000(x), x0, Newton(),Optim.Options(extended_trace=true,show_every=0,store_trace = true))  \n",
    "#     k_tot += result.iterations\n",
    "    \n",
    "# end\n",
    "# println(\"Average number of iterations for $(fun) averaged over $(n_x0) iterations: $(k_tot/n_x0)\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFGS from Optim.jl for n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Average number of iterations for Engvall with n = 1000 averaged over 1 iterations: 31.0\n",
      "Results of Optimization Algorithm\n",
      " * Algorithm: BFGS\n",
      " * Starting Point: [0.982197939559432,0.2027238160074285, ...]\n",
      " * Minimizer: [0.901026871530356,0.5458895424144249, ...]\n",
      " * Minimum: 1.108195e+03\n",
      " * Iterations: 31\n",
      " * Convergence: false\n",
      "   * |x - x'| < 1.0e-32: false \n",
      "     |x - x'| = 1.97e-08 \n",
      "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: false\n",
      "     |f(x) - f(x')| / |f(x)| = 1.23e-15 \n",
      "   * |g(x)| < 1.0e-08: false \n",
      "     |g(x)| = 2.44e-07 \n",
      "   * Stopped by an increasing objective: true\n",
      "   * Reached Maximum Number of Iterations: false\n",
      " * Objective Calls: 65\n",
      " * Gradient Calls: 65"
     ]
    }
   ],
   "source": [
    "n_x0 = 1\n",
    "n = 1000\n",
    "########################################################################################################\n",
    "k_tot = 0 \n",
    "\n",
    "for i = 1:n_x0\n",
    "    x0 = rand(n); \n",
    "    println(1)\n",
    "    result=optimize(x -> engvall_1000(x), x0, BFGS(),Optim.Options(extended_trace=true, show_every=1, store_trace = true))  \n",
    "    k_tot += result.iterations\n",
    "    \n",
    "end\n",
    "println(\"Average number of iterations for $(fun) averaged over $(n_x0) iterations: $(k_tot/n_x0)\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFGS from Optim.jl for n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of iterations for Engvall with n = 1000 averaged over 1 iterations: 32.0\n",
      "Results of Optimization Algorithm\n",
      " * Algorithm: BFGS\n",
      " * Starting Point: [0.10229007362775855,0.9727234237857976, ...]\n",
      " * Minimizer: [0.9010268569646798,0.5458894413357531, ...]\n",
      " * Minimum: 5.548668e+03\n",
      " * Iterations: 32\n",
      " * Convergence: false\n",
      "   * |x - x'| < 1.0e-32: false \n",
      "     |x - x'| = 3.43e-07 \n",
      "   * |f(x) - f(x')| / |f(x)| < 1.0e-32: false\n",
      "     |f(x) - f(x')| / |f(x)| = 9.83e-16 \n",
      "   * |g(x)| < 1.0e-08: false \n",
      "     |g(x)| = 1.35e-06 \n",
      "   * Stopped by an increasing objective: true\n",
      "   * Reached Maximum Number of Iterations: false\n",
      " * Objective Calls: 67\n",
      " * Gradient Calls: 67"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "########################################################################################################\n",
    "k_tot = 0 \n",
    "\n",
    "for i = 1:n_x0\n",
    "    \n",
    "    x0 = rand(n); \n",
    "    result=optimize(x -> engvall_5000(x), x0, BFGS(),Optim.Options(extended_trace=true,show_every=0,store_trace = true))  \n",
    "    k_tot += result.iterations\n",
    "    \n",
    "end\n",
    "println(\"Average number of iterations for $(fun) averaged over $(n_x0) iterations: $(k_tot/n_x0)\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our own L-BFGS for n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "Results: \n",
      "=========================================================\n",
      "Average number of iterations for n = 1000, averaged over 10 iterations: 38.3\n"
     ]
    }
   ],
   "source": [
    "include(\"engvall.jl\")\n",
    "n_x0 = 10\n",
    "n = 1000\n",
    "maxIt = 1000\n",
    "println(\"\\n=========================================================\\nResults: \\n=========================================================\")\n",
    "k_tot = 0 \n",
    "\n",
    "for i = 1:n_x0\n",
    "    x0 = rand(n); \n",
    "    x1, f1, k, pos=lbfgs!(engvall_1000, x0, 1000, m); \n",
    "    k_tot += k\n",
    "end\n",
    "println(\"Average number of iterations for n = $n, averaged over $(n_x0) iterations: $(k_tot/n_x0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "Results: \n",
      "=========================================================\n",
      "Average memory in [kB] allocated form = 2, averaged over 10 iterations: 93924.4656\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n=========================================================\\nResults: \\n=========================================================\")\n",
    "mem_tot = 0 \n",
    "m = 2\n",
    "n = 1000\n",
    "\n",
    "for i = 1:n_x0\n",
    "    x0 = rand(n); \n",
    "    mem = @allocated lbfgs!(engvall_1000, x0, 1000, m)\n",
    "    mem_tot += mem\n",
    "end\n",
    "\n",
    "println(\"Average memory in [kB] allocated form = $m, averaged over $(n_x0) iterations: $(mem_tot/(n_x0*1000))\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our own L-BFGS for n = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "Results: \n",
      "=========================================================\n",
      "Average number of iterations for n = 5000, averaged over 10 iterations: 39.1\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "maxIt = 1000\n",
    "println(\"\\n=========================================================\\nResults: \\n=========================================================\")\n",
    "\n",
    "k_tot = 0 \n",
    "\n",
    "for i = 1:n_x0\n",
    "    x0 = rand(n); \n",
    "    x1, f1, k, pos=lbfgs!(engvall_5000, x0, 1000, m); \n",
    "    k_tot += k\n",
    "end\n",
    "println(\"Average number of iterations for n = $n, averaged over $(n_x0) iterations: $(k_tot/n_x0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================\n",
      "Results: \n",
      "=========================================================\n",
      "Average memory in [kB] allocated for m = 2, averaged over 10 iterations: 605443.5856\n"
     ]
    }
   ],
   "source": [
    "println(\"\\n=========================================================\\nResults: \\n=========================================================\")\n",
    "mem_tot = 0 \n",
    "m = 2\n",
    "n = 5000\n",
    "\n",
    "for i = 1:n_x0\n",
    "    x0 = rand(n); \n",
    "    mem = @allocated lbfgs!(engvall_5000, x0, 1000, m)\n",
    "    mem_tot += mem\n",
    "end\n",
    "\n",
    "println(\"Average memory in [kB] allocated for m = $m, averaged over $(n_x0) iterations: $(mem_tot/(n_x0*1000))\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
