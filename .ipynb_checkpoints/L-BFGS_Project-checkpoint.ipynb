{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\">18.335/6.337 Final Project - The L-BFGS algorithm</div>\n",
    "### <div style=\"text-align: center\">Created by Yusu Liu and Simon Batzner</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import different benchmarking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "easom (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"testfns.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lbfgs! (generic function with 3 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lbfgs!(F, x0, maxIt, m, τgrad=1e-6, verbose = 0)\n",
    "    \n",
    "    # params\n",
    "    # \n",
    "    # F:      function to be optimized\n",
    "    # x0:     initial guess\n",
    "    # maxIt:  maximum Iteration\n",
    "    # m:      number of input differences and gradient differences to be stored\n",
    "    # τgrad:  tolerance for norm of the slope\n",
    "\n",
    "\n",
    "    # returns: \n",
    "    # x1:     optimized variable\n",
    "    # f1:     function value at x1\n",
    "    # k       iteration number\n",
    "\n",
    "    k=0\n",
    "    n=length(x0)\n",
    "    Sm=zeros(n,m) # S_k=x_k+1-x_k\n",
    "    Ym=zeros(n,m) # Y_k=g_k+1-g_k\n",
    "    f0,g0=F(x0)\n",
    "    \n",
    "    # use the simplest line search to find step size\n",
    "    α, f1, g1 = backtracking(F,-g0,x0)\n",
    "    x1 = x0 - α.*g0\n",
    "    \n",
    "    # counter\n",
    "    k = 1\n",
    "\n",
    "    while true\n",
    "        \n",
    "        if k > maxIt\n",
    "            #println(\"Maximum number of iterations reached: $(k-1)\")\n",
    "            break; \n",
    "        end\n",
    "        \n",
    "        gnorm = norm(g0)\n",
    "        \n",
    "        if gnorm < τgrad\n",
    "            \n",
    "            break; \n",
    "        end\n",
    "        \n",
    "        s0 = x1-x0\n",
    "        y0 = g1-g0\n",
    "        \n",
    "        # println(\"y0=$y0\")\n",
    "        H0 = s0'*y0/(y0'*y0) # hessian diagonal satisfying secant condition\n",
    "\n",
    "        # update Sm and Ym\n",
    "        if k <= m\n",
    "            Sm[:,k]=s0\n",
    "            Ym[:,k]=y0\n",
    "            p=-approxInvHess(g1,Sm[:,1:k],Ym[:,1:k],H0)\n",
    "        # only keep m entries in Sm and Ym so purge the old ones\n",
    "            \n",
    "        elseif (k>m)\n",
    "            Sm[:,1:(m-1)]=Sm[:,2:m]\n",
    "            Ym[:,1:(m-1)]=Sm[:,2:m]\n",
    "            Sm[:,m]=s0\n",
    "            Ym[:,m]=y0\n",
    "            p=-approxInvHess(g1,Sm,Ym,H0)\n",
    "        end\n",
    "        \n",
    "        # new direction=p, find new step size\n",
    "        α, fs, gs=backtracking(F,p,x1)\n",
    "        \n",
    "        # update for next iteration\n",
    "        x0=x1\n",
    "        g0=g1\n",
    "        x1=x1+α.*p\n",
    "        f1=fs\n",
    "        g1=gs\n",
    "        k=k+1\n",
    "        \n",
    "        if verbose == 1 \n",
    "            println(\"Iteration: $k -- x = $x1\")\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    k=k-1\n",
    "    return x1, f1, k\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backtracking (generic function with 4 methods)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backtracking(F,d,x,r=0.5,c=1e-4,nmax=100)\n",
    "    \n",
    "    # params\n",
    "    # F: function to be optimized\n",
    "    # x: variable\n",
    "    # d: direction\n",
    "    # r: factor by which to reduce step size at each iteration\n",
    "    # c: parameter [0,1]\n",
    "    # nmax: max iteration\n",
    "\n",
    "    # return\n",
    "    # α step size\n",
    "    # fk1: function value at new x\n",
    "    # gkk: gradient at new x\n",
    "\n",
    "    #https://en.wikipedia.org/wiki/Backtracking_line_search\n",
    "    α=1\n",
    "    fk,gk=F(x)\n",
    "    xx=x\n",
    "    x=x+α*d\n",
    "    fk1,gk1=F(x)\n",
    "    n=1\n",
    "    \n",
    "    while fk1>fk+c*α*(gk'*d) && n < nmax\n",
    "        n=n+1\n",
    "        α=α*0.5\n",
    "        x=xx+α*d\n",
    "        fk1,gk1=F(x)\n",
    "    end\n",
    "    \n",
    "    return α, fk1, gk1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "approxInvHess (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function approxInvHess(g,S,Y,H0)\n",
    "\n",
    "    # params: \n",
    "    # g: gradient nx1 vector\n",
    "    # S: nxk matrixs storing S[i]=x[i+1]-x[i]\n",
    "    # Y: nxk matrixs storing Y[i]=g[i+1]-g[i]\n",
    "    # H0: initial hessian diagnol scalar\n",
    "\n",
    "    # return:\n",
    "    # p:  the approximate inverse hessian multiplied by the gradient g\n",
    "    #     which is the new direction\n",
    "    #\n",
    "    # notation follows: https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
    "\n",
    "    n,k=size(S)\n",
    "    rho=zeros(k)\n",
    "    for i=1:k\n",
    "        rho[i]=1/(Y[:,i]'*S[:,i])\n",
    "    end\n",
    "\n",
    "    q=zeros(n,k+1)\n",
    "    r=zeros(n,1)\n",
    "    α=zeros(k,1)\n",
    "    β=zeros(k,1)\n",
    "\n",
    "    q[:,k+1]=g\n",
    "\n",
    "    for i=k:-1:1\n",
    "        α[i]=rho[i]*S[:,i]'*q[:,i+1]\n",
    "        q[:,i]=q[:,i+1]-α[i]*Y[:,i]\n",
    "    end\n",
    "\n",
    "    z=H0*q[:,1]\n",
    "\n",
    "\n",
    "    for i=1:k\n",
    "        β[i]=rho[i]*Y[:,i]'*z\n",
    "        z=z+S[:,i]*(α[i]-β[i])\n",
    "    end\n",
    "\n",
    "    p=z\n",
    "\n",
    "    return p\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_range (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_range(a0, a1, b0, b1, step, tol)\n",
    "    x1_opt = [1.0, 1.0]\n",
    "    \n",
    "    for a in a0:step:a1\n",
    "        for b in b0:step:b1\n",
    "            \n",
    "            x0 = [a, b]\n",
    "            x1, f1, k=lbfgs!(rosenbrock, x0, 100, 2); \n",
    "            \n",
    "            if (norm(x1 - x1_opt)) < tol\n",
    "                break;\n",
    "            else\n",
    "                println(\"======\\nfailed for: x0 = [$a, $b]\")\n",
    "                println(\"x1 found was: $(x1)\\n\")\n",
    "            end\n",
    "            \n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======\n",
      "failed for: x0 = [-1.3, -2.0]\n",
      "x1 found was: [NaN, NaN]\n",
      "\n",
      "======\n",
      "failed for: x0 = [-0.9, -2.0]\n",
      "x1 found was: [NaN, NaN]\n",
      "\n",
      "======\n",
      "failed for: x0 = [-0.6, -2.0]\n",
      "x1 found was: [1.0, 1.0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0], 3.1739028310543608e-15, 25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial guess\n",
    "x0=[10, 0.1] \n",
    "x1_opt = [1.0, 1.0]\n",
    "m = 2\n",
    "\n",
    "# define test function\n",
    "function rosenbrock(x::Vector)\n",
    "    F=(1-x[1])^2+100*(x[2]-x[1]^2)^2\n",
    "    d=[-2*(1-x[1])-400*(x[2]-x[1]^2)*x[1],200 * (x[2] - x[1]^2)]\n",
    "   return F, d\n",
    "end\n",
    "\n",
    "# scan over range\n",
    "test_range(-2, 2, -2, 2, 0.1, 1e-6)\n",
    "\n",
    "x0 = [1, 1.5]\n",
    "x1, f1, k = lbfgs!(rosenbrock, x0, 100, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try different optimization test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3.00034, 1.9907], 0.0014051682266910735, 10)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs!(himmelblau, x0, 10, 2, 1e-6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.00001, 3.0], 1.0350538584755263e-10, 10)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs!(booth, x0, 10, 2, 1e-6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0122283, 0.0128619], 0.007683875360763537, 10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs!(bohachevsky1, x0, 10, 2, 1e-6, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.305, 1.30499], -8.110223889894006e-5, 8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbfgs!(easom, x0, 10, 2, 1e-6, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time elapsed for 10 evaluations of rosenbrock: 0.009143528000000001\n",
      "\n",
      "Time elapsed for 10 evaluations of himmelblau: 0.033537361\n",
      "\n",
      "Time elapsed for 10 evaluations of booth: 0.039275296999999994\n",
      "\n",
      "Time elapsed for 10 evaluations of bohachevsky1: 0.052118979999999995\n",
      "\n",
      "Time elapsed for 10 evaluations of easom: 0.05443652199999999\n"
     ]
    }
   ],
   "source": [
    "maxIt = 100\n",
    "m = 2\n",
    "tol = 1e-6\n",
    "verbose = 0\n",
    "range = 10\n",
    "t = 0.0\n",
    "\n",
    "funs = [rosenbrock, himmelblau, booth, bohachevsky1, easom]\n",
    "\n",
    "for fun in funs\n",
    "    for i in 1:range\n",
    "        x0 = [rand(-1:0.1:1), rand(-1:0.1:1)]\n",
    "        t += @elapsed lbfgs!(fun, x0, maxIt, m, tol, verbose)\n",
    "    end\n",
    "    \n",
    "    println(\"\\nTime elapsed for $(range) evaluations of $(fun): $t\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
